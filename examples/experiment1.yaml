project_name: "JengaAI_NER_Experiment"

model:
  base_model: "distilbert-base-uncased"
  dropout: 0.1
  fusion:  # ADD THIS SECTION
    type: "attention"
    hidden_size: 768

tokenizer:
  max_length: 256
  padding: "max_length"
  truncation: true

training:
  output_dir: "./unified_results_ner"
  learning_rate: 2.0e-5
  batch_size: 8
  num_epochs: 5
  weight_decay: 0.01
  warmup_steps: 100
  eval_strategy: "epoch"
  save_strategy: "epoch"
  load_best_model_at_end: true
  metric_for_best_model: "eval_loss"
  greater_is_better: false
  early_stopping_patience: 3
  logging:
    service: "mlflow"
    experiment_name: "JengaAI_NER"

tasks:
  - name: "SwahiliNER"
    type: "ner"
    data_path: "examples/ner_data.jsonl"
    heads:
      - name: "ner_head"
        num_labels: 13 # Placeholder, will be determined from data
        weight: 1.0